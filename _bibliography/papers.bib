---
---

---
---

@string{aps = {American Physical Society}}

@misc{rahmani2024syndllargescalesynthetictest,
      abbr={arXiv},
      title={SynDL: A Large-Scale Synthetic Test Collection for Passage Retrieval}, 
      author={Hossein A. Rahmani and Xi Wang and Emine Yilmaz and Nick Craswell and Bhaskar Mitra and Paul Thomas},
      year={2024},
      eprint={2408.16312},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2408.16312},
      html={https://arxiv.org/abs/2408.16312},
      website={https://rahmanidashti.github.io/SynDL/},
      code={https://github.com/rahmanidashti/SynDL} 
}

@misc{rahmani2024report1stworkshoplarge,
      abbr={arXiv},
      title={Report on the 1st Workshop on Large Language Model for Evaluation in Information Retrieval (LLM4Eval 2024) at SIGIR 2024}, 
      author={Hossein A. Rahmani and Clemencia Siro and Mohammad Aliannejadi and Nick Craswell and Charles L. A. Clarke and Guglielmo Faggioli and Bhaskar Mitra and Paul Thomas and Emine Yilmaz},
      year={2024},
      eprint={2408.05388},
      archivePrefix={arXiv},
      primaryClass={cs.IR},
      url={https://arxiv.org/abs/2408.05388},
      html={https://arxiv.org/abs/2408.05388},
      website={https://llm4eval.github.io/},
      abstract={The first edition of the workshop on Large Language Model for Evaluation in Information Retrieval (LLM4Eval 2024) took place in July 2024, co-located with the ACM SIGIR Conference 2024 in the USA (SIGIR 2024). The aim was to bring information retrieval researchers together around the topic of LLMs for evaluation in information retrieval that gathered attention with the advancement of large language models and generative AI. Given the novelty of the topic, the workshop was focused around multi-sided discussions, namely panels and poster sessions of the accepted proceedings papers.} 
}

@article{rahmani2024llmjudge,
  abbr={arXiv},
  title={LLMJudge: LLMs for Relevance Judgments},
  author={Rahmani, Hossein A and Yilmaz, Emine and Craswell, Nick and Mitra, Bhaskar and Thomas, Paul and Clarke, Charles LA and Aliannejadi, Mohammad and Siro, Clemencia and Faggioli, Guglielmo},
  journal={arXiv preprint arXiv:2408.08896},
  year={2024},
  url={https://arxiv.org/abs/2408.08896},
  html={https://arxiv.org/abs/2408.08896},
  website={https://llm4eval.github.io/challenge/},
  code={https://github.com/llm4eval/LLMJudge}
}

@article{wu2024understandingroleuserprofile,
  abbr={arXiv},
  title={Understanding the Role of User Profile in the Personalization of Large Language Models}, 
  author={Bin Wu and Zhengyan Shi and Hossein A. Rahmani and Varsha Ramineni and Emine Yilmaz},
  year={2024},
  eprint={2406.17803},
  archivePrefix={arXiv},
  journal = {arXiv:2406.17803},
  arxiv={2406.17803},
  abstract={Utilizing user profiles to personalize Large Language Models (LLMs) has been shown to enhance the performance on a wide range of tasks. However, the precise role of user profiles and their effect mechanism on LLMs remains unclear. This study first confirms that the effectiveness of user profiles is primarily due to personalization information rather than semantic information. Furthermore, we investigate how user profiles affect the personalization of LLMs. Within the user profile, we reveal that it is the historical personalized response produced or approved by users that plays a pivotal role in personalizing LLMs. This discovery unlocks the potential of LLMs to incorporate a greater number of user profiles within the constraints of limited input length. As for the position of user profiles, we observe that user profiles integrated into different positions of the input context do not contribute equally to personalization. Instead, where the user profile that is closer to the beginning affects more on the personalization of LLMs. Our findings reveal the role of user profiles for the personalization of LLMs, and showcase how incorporating user profiles impacts performance providing insight to leverage user profiles effectively.},
  url={https://arxiv.org/abs/2406.17803},
  code={https://github.com/Bingo-W/Personalisation-in-LLM} 
}

@inproceedings{10.1145/3664190.3672507,
  abbr={ICTIR},
  author = {Naghiaei, Mohammadmehdi and Dehghan, Mahdi and Rahmani, Hossein A. and Azizi, Javad and Aliannejadi, Mohammad},
  title = {Personalized Beyond-accuracy Calibration in Recommendation},
  year = {2024},
  url = {https://doi.org/10.1145/3664190.3672507},
  abstract = {Recommender systems usually aim to optimize accuracy in a supervised setting. Due to various data biases, they often fail to enhance other critical qualities that go beyond accuracy, such as diversity, novelty, and serendipity. Prior studies focus on addressing the bias in beyond-accuracy metrics from the provider's perspective, such as increasing the overall diversity of recommendations to combat popularity bias. In this work, we take a user-centric approach to this problem and demonstrate that users have distinct preferences for beyond-accuracy metrics. We hypothesize that users have an implicit behavioral model that goes beyond optimizing their choices only for accuracy. For instance, we assume that a user's purchase behavior is a mix of items that are more familiar to the user (optimizing for accuracy), and new items that are aimed for exploration (optimizing for novelty). We argue that a recommender system should reflect users' interest in such beyond-accuracy metrics. This perspective allows for a more holistic understanding of users' behavior and preferences leading to more fine-grained personalized recommendations. To this end, we propose a post-ranking greedy optimization algorithm that ensures recommendations are not only accurate but also meet users' beyond-accuracy preferences. Through extensive experiments, we demonstrate our proposed method's ability to balance the trade-off between ranking accuracy and user-centric beyond-accuracy preferences.},
  booktitle = {ACM SIGIR International Conference on Theory of Information Retrieval},
  pages = {107–116},
  numpages = {10},
  keywords = {calibration, fairness, re-ranking, recommender systems},
  location = {Washington DC, USA},
  series = {ICTIR '24}
}

@inproceedings{10.1145/3626772.3657992,
  abbr={SIGIR},
  author = {Rahmani, Hossein A. and Siro, Clemencia and Aliannejadi, Mohammad and Craswell, Nick and Clarke, Charles L. A. and Faggioli, Guglielmo and Mitra, Bhaskar and Thomas, Paul and Yilmaz, Emine},
  title = {LLM4Eval: Large Language Model for Evaluation in IR},
  year = {2024},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3626772.3657992},
  doi = {10.1145/3626772.3657992},
  abstract = {Large language models (LLMs) have demonstrated increasing task-solving abilities not present in smaller models. Utilizing the capabilities and responsibilities of LLMs for automated evaluation (LLM4Eval) has recently attracted considerable attention in multiple research communities. For instance, LLM4Eval models have been studied in the context of automated judgments, natural language generation, and retrieval augmented generation systems. We believe that the information retrieval community can significantly contribute to this growing research area by designing, implementing, analyzing, and evaluating various aspects of LLMs with applications to LLM4Eval tasks. The main goal of LLM4Eval workshop is to bring together researchers from industry and academia to discuss various aspects of LLMs for evaluation in information retrieval, including automated judgments, retrieval-augmented generation pipeline evaluation, altering human evaluation, robustness, and trustworthiness of LLMs for evaluation in addition to their impact on real-world applications. We also plan to run an automated judgment challenge prior to the workshop, where participants will be asked to generate labels for a given dataset while maximising correlation with human judgments. The format of the workshop is interactive, including roundtable and keynote sessions and tends to avoid the one-sided dialogue of a mini-conference.},
  booktitle = {ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages = {3040–3043},
  numpages = {4},
  keywords = {automated evaluation, generative models, large language models},
  location = {Washington DC, USA},
  series = {SIGIR '24},
  website={https://llm4eval.github.io/}
}

@inproceedings{rahmani2024synthetic,
abbr={SIGIR},
author = {Rahmani, Hossein A. and Craswell, Nick and Yilmaz, Emine and Mitra, Bhaskar and Campos, Daniel},
title = {Synthetic Test Collections for Retrieval Evaluation},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Test collections play a vital role in evaluation of information retrieval (IR) systems. Obtaining a diverse set of user queries for test collection construction can be challenging, and acquiring relevance judgments, which indicate the appropriateness of retrieved documents to a query, is often costly and resource-intensive. Generating synthetic datasets using Large Language Models (LLMs) has recently gained significant attention in various applications. In IR, while previous work exploited the capabilities of LLMs to generate synthetic queries or documents to augment training data and improve the performance of ranking models, using LLMs for constructing synthetic test collections is relatively unexplored. Previous studies demonstrate that LLMs have the potential to generate synthetic relevance judgments for use in the evaluation of IR systems. In this paper, we comprehensively investigate whether it is possible to use LLMs to construct fully synthetic test collections by generating not only synthetic judgments but also synthetic queries. In particular, we analyse whether it is possible to construct reliable synthetic test collections and the potential risks of bias such test collections may exhibit towards LLM-based models. Our experiments indicate that using LLMs it is possible to construct synthetic test collections that can reliably be used for retrieval evaluation.},
booktitle = {ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR)},
series = {SIGIR '24},
arxiv={2405.07767},
code={https://github.com/rahmanidashti/SyntheticTestCollections},
poster={https://www.slideshare.net/slideshow/synthetic-test-collections-for-retrieval-evaluation-poster/270080247},
year={2024},
}

@article{rahmani2024tors,
  abbr={ACM TORS},
  author = {Rahmani, Hossein A. and Naghiaei, Mohammadmehdi and Deldjoo, Yashar},
  title = {A Personalized Framework for Consumer and Producer Group Fairness Optimization in Recommender Systems},
  year = {2024},
  issue_date = {September 2024},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  volume = {2},
  number = {3},
  url = {https://doi.org/10.1145/3651167},
  doi = {10.1145/3651167},
  abstract = {In recent years, there has been an increasing recognition that when machine learning (ML) algorithms are used to automate decisions, they may mistreat individuals or groups, with legal, ethical, or economic implications. Recommender systems are prominent examples of these ML systems that aid users in making decisions. The majority of past literature research on recommender systems fairness treats user and item fairness concerns independently, ignoring the fact that recommender systems function in a two-sided marketplace. In this article, we propose CP-FairRank, an optimization-based re-ranking algorithm that seamlessly integrates fairness constraints from both the consumer and producer side in a joint objective framework. The framework is generalizable and may take into account varied fairness settings based on group segmentation, recommendation model selection, and domain, which is one of its key characteristics. For instance, we demonstrate that the system may jointly increase consumer and producer fairness when (un)protected consumer groups are defined on the basis of their&nbsp;activity level and&nbsp;main-streamness, while producer groups are defined according to their popularity level. For empirical validation, through large-scale on eight datasets and four mainstream collaborative filtering recommendation models, we demonstrate that our proposed strategy is able to improve both consumer and producer fairness without compromising or very little overall recommendation quality, demonstrating the role algorithms may play in avoiding data biases. Our results on different group segmentation also indicate that the amount of improvement can vary and is dependent on group segmentation, indicating that the amount of bias produced and how much the algorithm can improve it depend on the protected group definition, a factor that, to our knowledge, has not been examined in great depth in previous studies but rather is highlighted by the results discovered in this study.},
  journal = {ACM Transactions on Recommender Systems (TORS)},
  articleno = {19},
  numpages = {24},
  code={https://github.com/rahmanidashti/CPFairRank},
  arxiv={2402.00485},
  keywords = {Responsible IR, recommender systems, fairness, ranking, bias mitigation, consumer and provider, multi-stakeholder}
}

@inproceedings{rahmani-etal-2024-clarifying,
  abbr={EACL},
  title={Clarifying the Path to User Satisfaction: An Investigation into Clarification Usefulness},
  author={Rahmani, Hossein A. and Wang, Xi and Aliannejadi, Mohammad and Naghiaei, Mohammadmehdi and Yilmaz, Emine},
  booktitle={European Chapter of the Association for Computational Linguistics (EACL)},
  year={2024},
  publisher={Association for Computational Linguistics},
  pages={1266--1277},
  abstract={Clarifying questions are an integral component of modern information retrieval systems, directly impacting user satisfaction and overall system performance. Poorly formulated questions can lead to user frustration and confusion, negatively affecting the system{'}s performance. This research addresses the urgent need to identify and leverage key features that contribute to the classification of clarifying questions, enhancing user satisfaction. To gain deeper insights into how different features influence user satisfaction, we conduct a comprehensive analysis, considering a broad spectrum of lexical, semantic, and statistical features, such as question length and sentiment polarity. Our empirical results provide three main insights into the qualities of effective query clarification: (1) specific questions are more effective than generic ones; (2) the subjectivity and emotional tone of a question play a role; and (3) shorter and more ambiguous queries benefit significantly from clarification. Based on these insights, we implement feature-integrated user satisfaction prediction using various classifiers, both traditional and neural-based, including random forest, BERT, and large language models. Our experiments show a consistent and significant improvement, particularly in traditional classifiers, with a minimum performance boost of 45{\%}. This study presents invaluable guidelines for refining the formulation of clarifying questions and enhancing both user satisfaction and system performance.},
  url={https://arxiv.org/abs/2402.01934},
  html={https://aclanthology.org/2024.findings-eacl.84/},
  slides={https://www.slideshare.net/slideshow/clarification-questions-usefulness-slides/271793051},
  code={https://github.com/rahmanidashti/CQSatisfaction}
}

@article{karimi2023provider,
  abbr={FAccTRec@RecSys},
  title={Provider Fairness and Beyond-Accuracy Trade-offs in Recommender Systems},
  author={Karimi, Saeedeh and Rahmani, Hossein A. and Naghiaei, Mohammadmehdi and Safari, Leila},
  journal={FAccTRec Workshop on Responsible Recommendation (FAccTRec@RecSys)},
  arxiv={2309.04250},
  year={2023},
  slides={https://www.slideshare.net/SaeedRahmani9/beyondaccuracy-provider-fairness-slides},
  code={https://github.com/rahmanidashti/BeyondAccProvider},
  presentation={https://youtu.be/6QLAvZCfEAM?si=Gn6E-vWZ_FT_o2QH},
  html={https://facctrec.github.io/facctrec2023/program/}
}

@article{rahmani2023acqsurvey,
  abbr={ACL},
  title={A Survey on Asking Clarification Questions Datasets in Conversational Systems}, 
  author={Hossein A. Rahmani and Xi Wang and Yue Feng and Qiang Zhang and Emine Yilmaz and Aldo Lipani},
  journal={Annual Meeting of the Association for Computational Linguistics (ACL)},
  abstract={The ability to understand a user's underlying needs is critical for conversational systems, especially with limited input from users in a conversation. Thus, in such a domain, Asking Clarification Questions (ACQs) to reveal users' true intent from their queries or utterances arise as an essential task. However, it is noticeable that a key limitation of the existing ACQs studies is their incomparability, from inconsistent use of data, distinct experimental setups and evaluation strategies. Therefore, in this paper, to assist the development of ACQs techniques, we comprehensively analyse the current ACQs research status, which offers a detailed comparison of publicly available datasets, and discusses the applied evaluation metrics, joined with benchmarks for multiple ACQs-related tasks. In particular, given a thorough analysis of the ACQs task, we discuss a number of corresponding research directions for the investigation of ACQs as well as the development of conversational systems.},
  arxiv={2305.15933},
  year={2023},
  url={https://aclanthology.org/2023.acl-long.152/},
  poster={https://www.slideshare.net/SaeedRahmani9/acqsurvey-poster},
  slides={https://www.slideshare.net/SaeedRahmani9/acqsurvey-slides},
  code={https://github.com/rahmanidashti/ACQSurvey},
  html={https://virtual2023.aclweb.org/paper_P3852.html}
}

@article{shi2023and,
  abbr={IGLU@NeurIPS},
  title={When and what to ask through world states and text instructions: Iglu nlp challenge solution},
  author={Shi, Zhengxiang and Ramos, Jerome and Kim, To Eun and Wang, Xi and Rahmani, Hossein A. and Lipani, Aldo},
  journal={Neural Information Processing Systems IGLU Workshop (IGLU@NeurIPS)},
  abstract={In collaborative tasks, effective communication is crucial for achieving joint goals. One such task is collaborative building where builders must communicate with each other to construct desired structures in a simulated environment such as Minecraft. We aim to develop an intelligent builder agent to build structures based on user input through dialogue. However, in collaborative building, builders may encounter situations that are difficult to interpret based on the available information and instructions, leading to ambiguity. In the NeurIPS 2022 Competition NLP Task, we address two key research questions, with the goal of filling this gap: when should the agent ask for clarification, and what clarification questions should it ask? We move towards this target with two sub-tasks, a classification task and a ranking task. For the classification task, the goal is to determine whether the agent should ask for clarification based on the current world state and dialogue history. For the ranking task, the goal is to rank the relevant clarification questions from a pool of candidates. In this report, we briefly introduce our methods for the classification and ranking task. For the classification task, our model achieves an F1 score of 0.757, which placed the 3rd on the leaderboard. For the ranking task, our model achieves about 0.38 for Mean Reciprocal Rank by extending the traditional ranking model. Lastly, we discuss various neural approaches for the ranking task and future direction.},
  arxiv={2305.05754},
  year={2023}
}

@inproceedings{salutari2023quantifying,
  abbr={PAKDD},
  title={Quantifying the Bias of Transformer-Based Language Models for African American English in Masked Language Modeling},
  author={Salutari, Flavia and Ramos, Jerome and Rahmani, Hossein A. and Linguaglossa, Leonardo and Lipani, Aldo},
  booktitle={Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)},
  pages={532--543},
  year={2023},
  publisher={Springer},
  abstract = {In recent years, groundbreaking transformer-based language models (LMs) have made tremendous advances in natural language processing (NLP) tasks. However, the measurement of their fairness with respect to different social groups still remains unsolved. In this paper, we propose and thoroughly validate an evaluation technique to assess the quality and bias of language model predictions on transcripts of both spoken African American English (AAE) and Spoken American English (SAE). Our analysis reveals the presence of a bias towards SAE encoded by state-of-the-art LMs such as BERT and DistilBERT and a lower bias in distilled LMs. We also observe a bias towards AAE in RoBERTa and BART. Additionally, we show evidence that this disparity is present across all the LMs when we only consider the grammar and the syntax specific to AAE.},
  series = {PAKDD '23},
  html={https://link.springer.com/chapter/10.1007/978-3-031-33374-3_42}
}

@inproceedings{10.1145/3511808.3557713,
abbr={CIKM},
author = {Naghiaei, Mohammadmehdi and Rahmani, Hossein A. and Aliannejadi, Mohammad and Sonboli, Nasim},
title = {Towards Confidence-Aware Calibrated Recommendation},
year = {2022},
isbn = {9781450392365},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511808.3557713},
doi = {10.1145/3511808.3557713},
abstract = {Recommender systems utilize users' historical data to learn and predict their future interests, providing them with suggestions tailored to their tastes. Calibration ensures that the distribution of recommended item categories is consistent with the user's historical data. Mitigating miscalibration brings various benefits to a recommender system. For example, it becomes less likely that a system overlooks categories with less interaction on a user's profile by only recommending popular categories. Despite the notable success, calibration methods have several drawbacks, such as limiting the diversity of the recommended items and not considering the calibration confidence. This work, presents a set of properties that address various aspects of a desired calibrated recommender system. Considering these properties, we propose a confidence-aware optimization-based re-ranking algorithm to find the balance between calibration, relevance, and item diversity, while simultaneously accounting for calibration confidence based on user profile size. Our model outperforms state-of-the-art methods in terms of various accuracy and beyond-accuracy metrics for different user groups.},
booktitle = {ACM International Conference on Information and Knowledge Management (CIKM)},
pages = {4344–4348},
numpages = {5},
keywords = {re-ranking, recommender systems, confidence, calibration},
location = {Atlanta, GA, USA},
series = {CIKM '22},
arxiv={2208.10192},
poster={https://www.slideshare.net/SaeedRahmani9/towards-confidenceaware-calibrated-recommendation-poster},
slides={https://www.slideshare.net/SaeedRahmani9/22cikmcalibrationslidespdf},
code={https://github.com/rahmanidashti/CalibrationFair},
html={https://dl.acm.org/doi/10.1145/3511808.3557713}
}

@inproceedings{10.1145/3523227.3551481,
abbr={RecSys},
author = {Rahmani, Hossein A. and Naghiaei, Mohammadmehdi and Tourani, Ali and Deldjoo, Yashar},
title = {Exploring the Impact of Temporal Bias in Point-of-Interest Recommendation},
year = {2022},
isbn = {9781450392785},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3523227.3551481},
doi = {10.1145/3523227.3551481},
abstract = {Recommending appropriate travel destinations to consumers based on contextual information such as their check-in time and location is a primary objective of Point-of-Interest (POI) recommender systems. However, the issue of contextual bias (i.e., how much consumers prefer one situation over another) has received little attention from the research community. This paper examines the effect of temporal bias, defined as the difference between users’ check-in hours, leisure vs.&nbsp;work hours, on the consumer-side fairness of context-aware recommendation algorithms. We believe that eliminating this type of temporal (and geographical) bias might contribute to a drop in traffic-related air pollution, noting that rush-hour traffic may be more congested. To surface effective POI recommendation, we evaluated the sensitivity of state-of-the-art context-aware models to the temporal bias contained in users’ check-in activities on two POI datasets, namely Gowalla and Yelp. The findings show that the examined context-aware recommendation models prefer one group of users over another based on the time of check-in and that this preference persists even when users have the same amount of interactions.},
booktitle = {ACM Conference on Recommender Systems (RecSys)},
pages = {598–603},
numpages = {6},
keywords = {Contextual Fairness, Recommender Systems, Fusion, POI},
location = {Seattle, WA, USA},
series = {RecSys '22},
arxiv={},
website={},
slides={#},
code={},
}

@article{NAGHIAEI2022100382,
abbr={Software Impacts},
title = {PyCPFair: A framework for consumer and producer fairness in recommender systems},
journal = {Software Impacts},
volume = {13},
pages = {100382},
year = {2022},
issn = {2665-9638},
doi = {https://doi.org/10.1016/j.simpa.2022.100382},
url = {https://www.sciencedirect.com/science/article/pii/S2665963822000835},
author = {Mohammadmehdi Naghiaei and Hossein A. Rahmani and Yashar Deldjoo},
keywords = {Fairness, Algorithmic fairness, Recommender systems, Optimization, Re-ranking, Multi-stakeholder},
abstract = {Fairness is a critical problem not only in scientific research but also in many real-life applications. Recent work in recommender systems mainly focuses on fairness in recommendations as an important aspect of measuring recommendations quality. This paper presents PyCPFair, a Python-based framework for consumer and producer fairness in recommender systems. The ease-of-use and flexibility of the presented framework have allowed reducing the development time and increased evaluation strategies of fairness models for recommender systems. The PyCPFair is written mainly in Python and the optimization solution is provided using MIP interface and Gurobi solver.},
arxiv={},
website={},
slides={#},
code={},
year={2022},
}

@article{RAHMANI2022117700,
abbr={ESWA},
title = {The role of context fusion on accuracy, beyond-accuracy, and fairness of point-of-interest recommendation systems},
journal = {Expert Systems with Applications},
volume = {205},
pages = {117700},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117700},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422009903},
author = {Hossein A. Rahmani and Yashar Deldjoo and Tommaso {di Noia}},
keywords = {Contextual information, Context-aware POI recommendation, Interpretability, Evaluation, Fairness, Beyond-accuracy},
abstract = {Point-of-interest (POI) recommendation is an essential service to location-based social networks (LBSNs), benefiting both users providing them the chance to explore new locations and businesses by discovering new potential customers. These systems learn the preferences of users and their mobility patterns to generate relevant POI recommendations. Previous studies have shown that incorporating contextual information such as geographical, temporal, social, and categorical substantially improves the quality of POI recommendations. However, fewer works have studied in-depth the multi-aspect benefits of context fusion on POI recommendation, in particular on beyond-accuracy, fairness, and interpretability of recommendations. In this work, we propose a linear regression-based fusion of POI contexts that effectively finds the best combination of contexts for each (i) user, or (ii) group of users from their historical interactions. The results of large-scale experiments on two popular datasets Gowalla and Yelp reveal several interesting findings. First, the proposed approach does not present significant loss in accuracy and unfairness of popularity bias as with classical collaborative baselines, and yet improves the beyond-accuracy of recommendation compared with existing context-aware (CA) approaches using heuristic context fusions; for instance, the proposed approach improves the accuracy and beyond-accuracy compare to best baseline model by 25% and 30%, respectively. Second, our proposed approach is interpretable, allowing to explain to the user why she has been recommended specific POIs, based on the learned context weights from user past check-ins; for example, if you are in Rome and our method recommends you a historical place like ‘Colosseum’, it can also provide an explanation why this item is recommended to you based on your personal preference on context (e.g., you were recommended to visit ‘Colosseum’ because in the past your visited historical places). Third, by analyzing the fairness of recommendation with respect to users (based on their activity levels) and items (based on the popularity of items), we found that a model which is recommend fairly on one dataset can recommend unfair on another dataset. Overall, our study suggests that appropriate context fusion is an essential element of an accurate, fair, and transparent POI recommendation system. We highlight that while we have tested the efficacy of our context-fusion methods on two popular CA recommendation models in the POI domain, namely GeoSoCa and LORE, our system can be flexibly utilized to extend the capability of other CA algorithms.},
arxiv={},
website={},
slides={#},
code={},
year={2022},
}

@inproceedings{10.1145/3511047.3536415,
abbr={UMAP},
author = {Rameez, Rikaz and Rahmani, Hossein A. and Yilmaz, Emine},
title = {ViralBERT: A User Focused BERT-Based Approach to Virality Prediction},
year = {2022},
isbn = {9781450392327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3511047.3536415},
doi = {10.1145/3511047.3536415},
abstract = {Recently, Twitter has become the social network of choice for sharing and spreading information to a multitude of users through posts called ‘tweets’. Users can easily re-share these posts to other users through ‘retweets’, which allow information to cascade to many more users, increasing its outreach. Clearly, being able to know the extent to which a post can be retweeted has great value in advertising, influencing and other such campaigns. In this paper we propose ViralBERT, which can be used to predict the virality of tweets using content- and user-based features. We employ a method of concatenating numerical features such as hashtags and follower numbers to tweet text, and utilise two BERT modules: one for semantic representation of the combined text and numerical features, and another module purely for sentiment analysis of text, as both the information within text and it’s ability to elicit an emotional response play a part in retweet proneness. We collect a dataset of 330k tweets to train ViralBERT and validate the efficacy of our model using baselines from current studies in this field. Our experiments show that our approach outperforms these baselines, with a 13\% increase in both F1 Score and Accuracy compared to the best performing baseline method. We then undergo an ablation study to investigate the importance of chosen features, finding that text sentiment and follower counts, and to a lesser extent mentions and following counts, are the strongest features for the model, and that hashtag counts are detrimental to the model.},
booktitle = {Adjunct Proceedings of the 30th ACM Conference on User Modeling, Adaptation and Personalization},
pages = {85–89},
numpages = {5},
keywords = {Virality prediction, User features, Twitter, BERT},
location = {Barcelona, Spain},
series = {UMAP '22 Adjunct},
arxiv={},
website={},
slides={#},
code={},
year={2022},
}

@inproceedings{10.1145/3477495.3531718,
abbr={SIGIR},
author = {Rahmani, Hossein A. and Naghiaei, Mohammadmehdi and Dehghan, Mahdi and Aliannejadi, Mohammad},
title = {Experiments on Generalizability of User-Oriented Fairness in Recommender Systems},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531718},
doi = {10.1145/3477495.3531718},
abstract = {Recent work in recommender systems mainly focuses on fairness in recommendations as an important aspect of measuring recommendations quality. A fairness-aware recommender system aims to treat different user groups similarly. Relevant work on user-oriented fairness highlights the discriminant behavior of fairness-unaware recommendation algorithms towards a certain user group, defined based on users' activity level. Typical solutions include proposing a user-centered fairness re-ranking framework applied on top of a base ranking model to mitigate its unfair behavior towards a certain user group i.e., disadvantaged group. In this paper, we re-produce a user-oriented fairness study and provide extensive experiments to analyze the dependency of their proposed method on various fairness and recommendation aspects, including the recommendation domain, nature of the base ranking model, and user grouping method. Moreover, we evaluate the final recommendations provided by the re-ranking framework from both user- (e.g., NDCG, user-fairness) and item-side (e.g., novelty, item-fairness) metrics. We discover interesting trends and trade-offs between the model's performance in terms of different evaluation metrics. For instance, we see that the definition of the advantaged/disadvantaged user groups plays a crucial role in the effectiveness of the fairness algorithm and how it improves the performance of specific base ranking models. Finally, we highlight some important open challenges and future directions in this field. We release the data, evaluation pipeline, and the trained models publicly on https://github.com/rahmanidashti/FairRecSys.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2755–2764},
numpages = {10},
keywords = {algorithmic fairness, fairness, re-ranking, recommender systems},
location = {Madrid, Spain},
series = {SIGIR '22},
arxiv={},
website={},
slides={#},
code={},
year={2022},
}

@inproceedings{10.1145/3477495.3531959,
abbr={SIGIR},
author = {Naghiaei, Mohammadmehdi and Rahmani, Hossein A. and Deldjoo, Yashar},
title = {CPFair: Personalized Consumer and Producer Fairness Re-Ranking for Recommender Systems},
year = {2022},
isbn = {9781450387323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3477495.3531959},
doi = {10.1145/3477495.3531959},
abstract = {Recently, there has been a rising awareness that when machine learning (ML) algorithms are used to automate choices, they may treat/affect individuals unfairly, with legal, ethical, or economic consequences. Recommender systems are prominent examples of such ML systems that assist users in making high-stakes judgments. A common trend in the previous literature research on fairness in recommender systems is that the majority of works treat user and item fairness concerns separately, ignoring the fact that recommender systems operate in a two-sided marketplace. In this work, we present an optimization-based re-ranking approach that seamlessly integrates fairness constraints from both the consumer and producer-side in a joint objective framework. We demonstrate through large-scale experiments on 8 datasets that our proposed method is capable of improving both consumer and producer fairness without reducing overall recommendation quality, demonstrating the role algorithms may play in minimizing data biases.},
booktitle = {Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {770–779},
numpages = {10},
keywords = {fair re-ranking, two-sided fairness, recommendation system},
location = {Madrid, Spain},
series = {SIGIR '22},
arxiv={},
website={},
slides={#},
code={},
year={2022},
}

@inproceedings{naghiaei2021fairbook,
  abbr={Bias@ECIR},
  title={The Unfairness of Popularity Bias in Book Recommendation},
  author={Naghiaei, Mohammadmehdi and Rahmani, Hossein A. and Dehghan, Mahdi},
  abstract={Recent studies have shown that recommendation systems commonly suffer from popularity bias. Popularity bias refers to the problem that popular items (i.e., frequently rated items) are recommended frequently while less popular items are recommended rarely or not at all. Researchers adopted two approaches to examining popularity bias: (i) from the users' perspective, by analyzing how far a recommendation system deviates from user's expectations in receiving popular items, and (ii) by analyzing the amount of exposure that long-tail items receive, measured by overall catalog coverage and novelty. In this paper, we examine the first point of view in the book domain, although the findings may be applied to other domains as well. To this end, we analyze the well-known Book-Crossing dataset and define three user groups based on their tendency towards popular items (i.e., Niche, Diverse, Bestseller-focused). Further, we evaluate the performance of nine state-of-the-art recommendation algorithms and two baselines (i.e., Random, MostPop) from both the accuracy (e.g., NDCG, Precision, Recall) and popularity bias perspectives. Our results indicate that most state-of-the-art recommendation algorithms suffer from popularity bias in the book domain, and fail to meet users' expectations with Niche and Diverse tastes despite having a larger profile size. Conversely, Bestseller-focused users are more likely to receive high-quality recommendations, both in terms of fairness and personalization. Furthermore, our study shows a tradeoff between personalization and unfairness of popularity bias in recommendation algorithms for users belonging to the Diverse and Bestseller groups, that is, algorithms with high capability of personalization suffer from the unfairness of popularity bias.},
  booktitle={Third International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR)},
  arxiv={2202.13446},
  website={https://rahmanidashti.github.io/FairBook/},
  slides={#},
  code={https://github.com/rahmanidashti/FairBook},
  year={2022},
}

@inproceedings{rahmani2021fairpoi,
  abbr={Bias@ECIR},
  selected={true},
  title={The Unfairness of Active Users and Popularity Bias in Point-of-Interest Recommendation},
  author={Rahmani, Hossein A. and Deldjoo, Yashar and Tourani, Ali and Naghiaei, Mohammadmehdi},
  abstract={Point-of-Interest (POI) recommender systems provide personalized recommendations to users and help businesses attract potential customers. Despite their success, recent studies suggest that highly data-driven recommendations could be impacted by data biases, resulting in unfair outcomes for different stakeholders, mainly consumers (users) and providers (items). Most existing fairness-related research works in recommender systems treat user fairness and item fairness issues individually, disregarding that RS work in a two-sided marketplace. This paper studies the interplay between (i) the unfairness of active users, (ii) the unfairness of popular items, and (iii) the accuracy (personalization) of recommendation as three angles of our study triangle. We group users into advantaged and disadvantaged levels to measure user fairness based on their activity level. For item fairness, we divide items into short-head, mid-tail, and long-tail groups and study the exposure of these item groups into the top-k recommendation list of users. Experimental validation of eight different recommendation models commonly used for POI recommendation (e.g., contextual, CF) on two publicly available POI recommendation datasets, Gowalla and Yelp, indicate that most well-performing models suffer seriously from the unfairness of popularity bias (provider unfairness). Furthermore, our study shows that most recommendation models cannot satisfy both consumer and producer fairness, indicating a trade-off between these variables possibly due to natural biases in data. We choose the POI recommendation as our test scenario; however, the insights should be trivially extendable on other domains.},
  booktitle={Third International Workshop on Algorithmic Bias in Search and Recommendation (Bias@ECIR)},
  arxiv={2202.13307},
  website={https://recsys-lab.github.io/FairPOI/},
  slides={#},
  code={https://github.com/RecSys-lab/FairPOI},
  year={2022},
}

@article{rahmani2022ContextsPOIs,
  abbr={TOIS},
  title = {A Systematic Analysis on the Impact of Contextual Information on Point-of-Interest Recommendation},
  author = {Hossein A. Rahmani and Mohammad Aliannejadi and Mitra Baratchi and Fabio Crestani},
  journal = {ACM Transactions on Information Systems (TOIS)},
  volume = {40},
  number = {4},
  pages = {1-35},
  year = {2022},
  issn = {},
  html = {},
  arxiv={2201.08150},
  html={https://doi.org/10.1145/3508478},
  slides={https://www.slideshare.net/SaeedRahmani9/contextspoi-slides},
  website={https://rahmanidashti.github.io/ContextsPOI/},
  code={https://github.com/rahmanidashti/ContextsPOI},
  abstract = {As the popularity of Location-based Social Networks (LBSNs) increases, designing accurate models for Point-of-Interest (POI) recommendation receives more attention. POI recommendation is often performed by incorporating contextual information into previously designed recommendation algorithms. Some of the major contextual information that has been considered in POI recommendation are the location attributes (i.e., exact coordinates of a location, category, and check-in time), the user attributes (i.e., comments, reviews, tips, and check-in made to the locations), and other information, such as the distance of the POI from user's main activity location, and the social tie between users. The right selection of such factors can significantly impact the performance of the POI recommendation. However, previous research does not consider the impact of the combination of these different factors. In this paper, we propose different contextual models and analyze the fusion of different major contextual information in POI recommendation. The major contributions of this paper are: (i) providing an extensive survey of context-aware location recommendation (ii) quantifying and analyzing the impact of different contextual information (e.g., social, temporal, spatial, and categorical) in the POI recommendation on available baselines and two new linear and non-linear models, that can incorporate all the major contextual information into a single recommendation model, and (iii) evaluating the considered models using two well-known real-world datasets. Our results indicate that while modeling geographical and temporal influences can improve recommendation quality, fusing all other contextual information into a recommendation model is not always the best strategy.}
}

@article{SEYEDHOSEINZADEH2022102858,
  abbr={IP&M},
  title = {Leveraging social influence based on users activity centers for point-of-interest recommendation},
  journal = {Information Processing & Management (IP&M)},
  volume = {59},
  number = {2},
  pages = {102858},
  year = {2022},
  issn = {0306-4573},
  doi = {https://doi.org/10.1016/j.ipm.2021.102858},
  html = {https://www.sciencedirect.com/science/article/pii/S0306457321003290},
  code={https://github.com/Seyedhosseinzadeh/SUCP},
  author = {Kosar Seyedhoseinzadeh and Hossein A. Rahmani and Mohsen Afsharchi and Mohammad Aliannejadi},
  keywords = {Social influence, Contextual information, Point-of-interest recommendation, Personalization},
  abstract = {Recommender Systems (RSs) aim to model and predict the user preference while interacting with items, such as Points of Interest (POIs). These systems face several challenges, such as data sparsity, limiting their effectiveness. In this paper, we address this problem by incorporating social, geographical, and temporal information into the Matrix Factorization (MF) technique. To this end, we model social influence based on two factors: similarities between users in terms of common check-ins and the friendships between them. We introduce two levels of friendship based on explicit friendship networks and high check-in overlap between users. We base our friendship algorithm on users’ geographical activity centers. The results show that our proposed model outperforms the state-of-the-art on two real-world datasets. More specifically, our ablation study shows that the social model improves the performance of our proposed POI recommendation system by 31% and 14% on the Gowalla and Yelp datasets in terms of Precision@10, respectively.}
}

@inproceedings{rahmani2021crowdbias,
  abbr={BCD@CSCW},
  title={Demographic Biases of Crowd Workers in Key Opinion Leaders Finding},
  author={Rahmani, Hossein A. and Yang, Jie},
  abstract={Key Opinion Leaders (KOLs) are people that have a strong influence and their opinions are listened to by people when making important decisions. Crowdsourcing provides an efficient and cost-effective means to gather data for the KOL finding task. However, data collected through crowdsourcing is affected by the inherent demographic biases of crowd workers. To avoid such demographic biases, we need to measure how biased each crowd worker is. In this paper, we propose a simple yet effective approach based on demographic information of candidate KOLs and their counterfactual value. We argue that it is effectiveness because of the extra information that we can consider together with labeled data to curate a less biased dataset.},
  booktitle={CSCW 2021 Workshop - Investigating and Mitigating Biases in Crowdsourced Data (BCD)},
  pages={29--32},
  arxiv={2110.09248},
  html={https://arxiv.org/pdf/2111.14322.pdf},
  year={2021},
}

@inproceedings{rahmani2020joint,
  abbr={ECIR},
  bibtex_show={true},
  selected={true},
  title={Joint Geographical and Temporal Modeling based on Matrix Factorization for Point-of-Interest Recommendation},
  author={Rahmani, Hossein A. and Aliannejadi, Mohammad and Baratchi, Mitra and Crestani, Fabio},
  abstract={With the popularity of Location-based Social Networks, Point-of-Interest (POI) recommendation has become an important task, which learns the users’ preferences and mobility patterns to recommend POIs. Previous studies show that incorporating contextual information such as geographical and temporal influences is necessary to improve POI recommendation by addressing the data sparsity problem. However, existing methods model the geographical influence based on the physical distance between POIs and users, while ignoring the temporal characteristics of such geographical influences. In this paper, we perform a study on the user mobility patterns where we find out that users’ check-ins happen around several centers depending on their current temporal state. Next, we propose a spatio-temporal activity-centers algorithm to model users’ behavior more accurately. Finally, we demonstrate the effectiveness of our proposed contextual model by incorporating it into the matrix factorization model under two different settings: (i) static and (ii) temporal. To show the effectiveness of our proposed method, which we refer to as STACP, we conduct experiments on two well-known real-world datasets acquired from Gowalla and Foursquare LBSNs. Experimental results show that the STACP model achieves a statistically significant performance improvement, compared to the state-of-the-art techniques. Also, we demonstrate the effectiveness of capturing geographical and temporal information for modeling users’ activity centers and the importance of modeling them jointly.},
  booktitle={European Conference on Information Retrieval (ECIR)},
  pages={205--219},
  year={2020},
  organization={Springer}
}

@inproceedings{rahmani2019category,
  abbr={ICTIR},
  bibtex_show={true},
  title={Category-Aware Location Embedding for Point-of-Interest Recommendation},
  author={Rahmani, Hossein A. and Aliannejadi, Mohammad and Mirzaei Zadeh, Rasoul and Baratchi, Mitra and Afsharchi, Mohsen and Crestani, Fabio},
  booktitle={Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval (ICTIR)},
  pages={173--176},
  year={2019}
}

@thesis{rahmani2016bscthesis,
  abbr={MSc Seminar},
  bibtex_show={true},
  author = {Rahmani, Hossein A.},
  title = {A Short Review on Point-of-Interest Recommender Systems},
  school = {University of Zanjan},
  pdf = {XXX},
  slides = {HosseinARahmani_MScSeminar_Slides.pdf},
  year = {2018}
}

@inproceedings{naderi2018ie,
  abbr = {DCBDP},
  bibtex_show = {true},
  title = {A Study of Recent Contributions on Information Extraction},
  author = {Naderi, Parisa and Rahmani, Hossein A. and Azizi, Shahrzad and Leila, Safari},
  booktitle = {Proceedings of the 4th National Conference on Distributed Computing and Big Data Processing (DCBDP)},
  arxiv = {1803.05667},
  year = {2018}
}

@inproceedings{rahmani2016protein,
  abbr={ICB},
  bibtex_show={true},
  title={Comparison of Tumor and Normal Cells Protein-Protein Interaction Network Parameters},
  author={Rahmani, Hossein A. and Khanteymoori, Alireza and Olyaee, Mohammad},
  abstract={In this paper, we compared cancerous and normal cell according to their protein-protein interaction network. Cancer is one of the complicated diseases and experimental investigations have been showed that protein interactions have an important role in the growth of cancer. We calculated some graph related parameters such as Number of Vertices, Number of Edges, Closeness, Graph Diameter, Graph Radius, Index of Aggregation, Connectivity, Number of Edges divided by the Number of Vertices, Degree, Cluster Coefficient, Subgraph Centrality, and Betweenness. Furthermore, the number of motifs and hubs in these networks have been measured. In this paper bone, breast, colon, kidney and liver benchmark datasets have been used for experiments. The experimental results show that Graph Degree Mean, Subgraph Centrality, Betweenness, and Hubs have higher values in the cancer cells and can be used as a measure to distinguish between normal and cancerous networks. The cancerous tissues of the five studied samples are denser in the interaction networks.},
  booktitle = {Proceedings of the 6th Iranian Conference on Bioinformatics (ICB)},
  arxiv = {1903.07537},
  website={https://rahmanidashti.github.io/PPINetworkAnalysis/},
  year={2016}
}

@thesis{rahmani2016bscthesis,
  abbr={BSc Thesis},
  bibtex_show={true},
  author = {Rahmani, Hossein A.},
  title = {Natural and Cancer Cells Detection using Analysis of Protein Interaction Networks (in Persian)},
  school = {University of Zanjan},
  pdf = {https://www.researchgate.net/profile/Hossein-A-Rahmani/publication/340309396_Natural_and_Cancer_Cells_Detection_using_Analysis_of_Protein_Interaction_Networks/links/5e83542492851c2f5270b1ff/Natural-and-Cancer-Cells-Detection-using-Analysis-of-Protein-Interaction-Networks.pdf},
  year = {2016}
}


